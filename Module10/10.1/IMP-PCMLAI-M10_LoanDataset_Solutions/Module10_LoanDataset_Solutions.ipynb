{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z70pI11NAboS"
   },
   "source": [
    "#Classification and Regression Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQSOK7b8AboX"
   },
   "source": [
    "    \n",
    "## Assignment overview\n",
    "\n",
    "Decision trees are a non-parametric supervised learning method used for classification and regression. Decision trees learn from data to approximate a curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.\n",
    "Decision trees build classification or regression models in the form of trees. They break down a data set into smaller and smaller subsets while incrementally developing the associated decision tree. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. Leaf nodes represent a classification or decision. The topmost decision node in a tree, which corresponds to the best predictor, is called the root node. \n",
    "\n",
    "\n",
    "\n",
    "This assignment is designed to help you apply the machine learning algorithms you have learnt using packages in Python. Python concepts, instruction, and starter code are embedded within this Jupyter Notebook to help guide you as you progress through the assignment. Remember to run the code of each code cell prior to submitting the assignment. Upon completing the assignment, we encourage you to compare your work against the solution file to perform a self-assessment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAdRyXGhAboY"
   },
   "source": [
    "## Index:\n",
    "\n",
    "#### Week 9:   Classification and regression trees\n",
    "\n",
    "\n",
    "- [Part 1](#part1)- Importing the data set and exploratory data analysis (EDA)\n",
    "- [Part 2](#part2)- Translate the categorical predictors into numerical predictors\n",
    "- [Part 3](#part3)- Shuffle the data set\n",
    "- [Part 4](#part4)- Calculate the accuracy of the Naïve benchmark on the validation set.\n",
    "- [Part 5](#part5)- Train a decision tree using the default settings\n",
    "- [Part 6](#part6)- Train a decision tree using different maximum depths for the tree\n",
    "- [Part 7](#part7)- Retrain the best classifier using all the samples\n",
    "\n",
    "\n",
    "\n",
    "## Classification and regression trees\n",
    "\n",
    "In Week 9, you learnt about classification using regression trees.\n",
    "The basic idea behind the algorithm for classification via regression trees can be summarised as follows:\n",
    "\n",
    "- Load the data set\n",
    "- Select the best attribute using Attribute Selection Measures (ASM) to split the records.\n",
    "- Make that attribute a decision node and break the data set into smaller subsets.\n",
    "- Start building the tree by repeating this process recursively for each child until one of the conditions will match:\n",
    "    - All the tuples belong to the same attribute value.\n",
    "    - There are no more remaining attributes.\n",
    "    - There are no more instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdpWayrpAboZ"
   },
   "source": [
    "## Predict defaults for student loans applications\n",
    "\n",
    "For this exercise, we will use the data set `loandata.xlsx` to predict defaults for student loans applications using regression trees. We will perform the following steps:\n",
    "\n",
    "1. Load the data set `loandata.xlsx` into Python.\n",
    "2. Translate the categorical predictors into numerical predictors. \n",
    "3. Shuffle the data set and split it into 50% training data, 25% validation data and 25% test data.\n",
    "4. Calculate the accuracy of the Naïve benchmark  on the validation set.\n",
    "5. Train a decision tree using the default settings.\n",
    "6. Retry the previous step using different maximum depths for the tree. \n",
    "7. Choose the most appropriate tree depth and justify your choice. Re-train the best classifier using all the samples from both the training and the validation set. Retrain the best classifier on all samples (including the test set) and describe the tree that you obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWjEWLOIAboa"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1 -  Importing the data set and exploratory data analysis (EDA)\n",
    "\n",
    "We begin by importing the necessary libraries. We will then use `pandas` to import the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t6f8DUSuAbob",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:04.799295Z",
     "start_time": "2023-11-01T23:15:03.978057Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree, ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSUtPaUmAboc"
   },
   "source": [
    "Notice that this week's data set is in `.xlsx` format.\n",
    "\n",
    "Complete the code cell below by adding the name of the data set as a `str` to `.read_excel()`. Assign the dataframe to the variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "izqtEmB2Abod",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.011320Z",
     "start_time": "2023-11-01T23:15:04.797460Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('loandata.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TatVemQuAbod"
   },
   "source": [
    "\n",
    "Before building any machine learning algorithms, we should explore the data.\n",
    "\n",
    "We begin by visualising the first ten rows of the dataframe `df` using the function `.head()`. By default, `.head()` displays the first five rows of a dataframe.\n",
    "\n",
    "Complete the code cell below by passing the desired number of rows as an `int` to the function `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g7W_G1XtAboe",
    "outputId": "ef922992-160a-4731-c53a-90ef9ef73434",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.027504Z",
     "start_time": "2023-11-01T23:15:05.012321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        field  graduationYear    loanAmount  selectiveCollege     sex Default\n0        STEM            2006  23159.580541                 0    Male      No\n1  HUMANITIES            2010  47498.061207                 0    Male     Yes\n2  HUMANITIES            2012  29637.519526                 0  Female      No\n3        STEM            2008  25369.577159                 1  Female      No\n4    BUSINESS            2013  42398.554574                 0    Male     Yes\n5  HUMANITIES            2012  39253.384259                 1  Female     Yes\n6        STEM            2005  48903.966851                 1    Male      No\n7        STEM            2007  30687.019114                 1    Male      No\n8        STEM            2005  31999.816866                 0    Male      No\n9  HUMANITIES            2005  45120.419948                 0  Female     Yes",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>field</th>\n      <th>graduationYear</th>\n      <th>loanAmount</th>\n      <th>selectiveCollege</th>\n      <th>sex</th>\n      <th>Default</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>STEM</td>\n      <td>2006</td>\n      <td>23159.580541</td>\n      <td>0</td>\n      <td>Male</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HUMANITIES</td>\n      <td>2010</td>\n      <td>47498.061207</td>\n      <td>0</td>\n      <td>Male</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HUMANITIES</td>\n      <td>2012</td>\n      <td>29637.519526</td>\n      <td>0</td>\n      <td>Female</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>STEM</td>\n      <td>2008</td>\n      <td>25369.577159</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BUSINESS</td>\n      <td>2013</td>\n      <td>42398.554574</td>\n      <td>0</td>\n      <td>Male</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HUMANITIES</td>\n      <td>2012</td>\n      <td>39253.384259</td>\n      <td>1</td>\n      <td>Female</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>STEM</td>\n      <td>2005</td>\n      <td>48903.966851</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>STEM</td>\n      <td>2007</td>\n      <td>30687.019114</td>\n      <td>1</td>\n      <td>Male</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>STEM</td>\n      <td>2005</td>\n      <td>31999.816866</td>\n      <td>0</td>\n      <td>Male</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HUMANITIES</td>\n      <td>2005</td>\n      <td>45120.419948</td>\n      <td>0</td>\n      <td>Female</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MA2FgoQAbof"
   },
   "source": [
    "For your convenience, here is a brief description of what some of the columns represent:\n",
    "    \n",
    "- field: the field in which each student is taking their studies in\n",
    "- graduationYear: the year in which each student graduated\n",
    "- loanAmount: the amount each student owns\n",
    "- selectiveCollege: binary valued column: 1 for students who attend a selective college, 0 for students that do not\n",
    "- sex: sex of the student\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIJVmkIwAbof"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2 -  Translate the categorical predictors into numerical predictors\n",
    "\n",
    "How do we handle categorical features?\n",
    "\n",
    "In most of the well-established machine learning systems, categorical variables are handled naturally. However, when dealing with decision trees using `scikit-learn`, we need to encode (translate) categorical features into numerical features.\n",
    "\n",
    "Arguably, the easiest way to achieve this is by using the `pandas` function `get_dummies()` that converts categorical variables into dummy/indicator variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byFOKjrSAbof"
   },
   "source": [
    "\n",
    "\n",
    "**Answer Question 1 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrqpVr7VAbog"
   },
   "source": [
    "Complete the code cell below by using the function on the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AYxXtfV4Abog",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.030807Z",
     "start_time": "2023-11-01T23:15:05.020683Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncL7bL9JAbog"
   },
   "source": [
    "Because we are only interested in the students that will apply for a student loan,  we will only need to keep the column `Default_Yes`.\n",
    "\n",
    "Complete the code cell below by using the function `.drop()` on `df` to eliminate the *column* `Default_no`. The `axis` parameter in `.drop()` controls whether the function acts on rows or columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VuX3rWbeAboh",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.031112Z",
     "start_time": "2023-11-01T23:15:05.024167Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df.drop(['Default_No'], axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXBcOBa8Aboh"
   },
   "source": [
    "Run the code cell below to visualise the new dataframe with the encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RhhH0E8QAboh",
    "outputId": "1f4695b6-4485-45c4-addb-c5dd0589cbbd",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.085684Z",
     "start_time": "2023-11-01T23:15:05.030398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      graduationYear    loanAmount  selectiveCollege  field_BUSINESS  \\\n0               2006  23159.580541                 0           False   \n1               2010  47498.061207                 0           False   \n2               2012  29637.519526                 0           False   \n3               2008  25369.577159                 1           False   \n4               2013  42398.554574                 0            True   \n...              ...           ...               ...             ...   \n1995            2006  34593.557949                 0            True   \n1996            2009  35146.672010                 0           False   \n1997            2012  47883.543619                 0           False   \n1998            2006  42817.102001                 1            True   \n1999            2008  47527.628215                 0            True   \n\n      field_HUMANITIES  field_STEM  sex_Female  sex_Male  Default_Yes  \n0                False        True       False      True        False  \n1                 True       False       False      True         True  \n2                 True       False        True     False        False  \n3                False        True        True     False        False  \n4                False       False       False      True         True  \n...                ...         ...         ...       ...          ...  \n1995             False       False        True     False        False  \n1996              True       False        True     False         True  \n1997             False        True       False      True        False  \n1998             False       False        True     False        False  \n1999             False       False       False      True        False  \n\n[2000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>graduationYear</th>\n      <th>loanAmount</th>\n      <th>selectiveCollege</th>\n      <th>field_BUSINESS</th>\n      <th>field_HUMANITIES</th>\n      <th>field_STEM</th>\n      <th>sex_Female</th>\n      <th>sex_Male</th>\n      <th>Default_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2006</td>\n      <td>23159.580541</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010</td>\n      <td>47498.061207</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012</td>\n      <td>29637.519526</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008</td>\n      <td>25369.577159</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2013</td>\n      <td>42398.554574</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>2006</td>\n      <td>34593.557949</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>2009</td>\n      <td>35146.672010</td>\n      <td>0</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>2012</td>\n      <td>47883.543619</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>2006</td>\n      <td>42817.102001</td>\n      <td>1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2008</td>\n      <td>47527.628215</td>\n      <td>0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKqn_DqTAboh"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part3'></a> \n",
    "\n",
    "### Part 3 - Shuffle the data set\n",
    "\n",
    "Now, we want to shuffle the data: one way of doing this is by converting our dataframe to a `NumPy` array and then using the `.shuffle()` function to achieve this. Run the code cell below to convert the `df` into a `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N_tQUjtSAboh",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.087491Z",
     "start_time": "2023-11-01T23:15:05.032965Z"
    }
   },
   "outputs": [],
   "source": [
    "Xy=np.array(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdgkwsUSAboi"
   },
   "source": [
    "For reproducibility, set the random seed = 2. You can do this by using the `NumPy` function `random.seed()`. Assign your seed to the variable `seed`. Next, complete the code cell below by using the function `random.shuffle()` on `Xy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eghkATQpAboi",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.088097Z",
     "start_time": "2023-11-01T23:15:05.036274Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = np.random.seed(2)\n",
    "np.random.shuffle(Xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNKo0ShMAboi"
   },
   "source": [
    "Before splitting the data into a training set, a test set, and a validation set, we need to divide `Xy` into two arrays: the first one, `X`, a 2D array containing all the predictors and the second, `y`, is a 1D array with the response. \n",
    "\n",
    "Run the code cell below to generate `X`. Complete the remaining code to define `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IGQ5qbqZAboi",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.088235Z",
     "start_time": "2023-11-01T23:15:05.038292Z"
    }
   },
   "outputs": [],
   "source": [
    "X=Xy[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PM6zZ56uAboj",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.088351Z",
     "start_time": "2023-11-01T23:15:05.041661Z"
    }
   },
   "outputs": [],
   "source": [
    "y=Xy[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBmfJPqdAboj"
   },
   "source": [
    "Because we need to split into sets with certain dimensions according to the instructions given above, it would be useful to know how big our `X` and `y` are.\n",
    "\n",
    "Run the code cell below to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pleDOOG-Aboj",
    "outputId": "4eb0c11a-d15a-4d1b-9e68-4fc799570ad6",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.089544Z",
     "start_time": "2023-11-01T23:15:05.043588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VacVHSsAboj"
   },
   "source": [
    "Next, we need to split the messages into into 50% training data, 25% validation data, and 25% test data.\n",
    "\n",
    "Run the code below to split `X` into training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DZzcsAGyAboj",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.089675Z",
     "start_time": "2023-11-01T23:15:05.045966Z"
    }
   },
   "outputs": [],
   "source": [
    "trainsize = 1000\n",
    "trainplusvalsize = 500\n",
    "X_train=X[:trainsize]\n",
    "X_val=X[trainsize:trainsize + trainplusvalsize]\n",
    "X_test=X[trainsize + trainplusvalsize:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bw1r665jAboj"
   },
   "source": [
    "Following the syntax used above, complete the cell below to split `y` into training set, a validation set, and a test set.\n",
    "\n",
    "**HINT:** Remember that `y` is a 1D array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5WAkSNuHAboj",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.089790Z",
     "start_time": "2023-11-01T23:15:05.048379Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train=y[:trainsize]\n",
    "y_val=y[trainsize:trainsize + trainplusvalsize]\n",
    "y_test=y[trainsize + trainplusvalsize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UzhkrFDAbok"
   },
   "source": [
    "[Back to top](#Index:)\n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4 - Calculate the accuracy of the Naïve benchmark on the validation set\n",
    "\n",
    "In this part, we want to calculate the accuracy of the Naïve benchmarch on both the `y` training and validation sets. In other words, we want to understand how accurate our predictions would be if we assumed that no one defaulted on their student loans.\n",
    "\n",
    "Accuracy can be computed by comparing actual test set values and predicted values. In this example, the formulae to compute accuracy are:\n",
    "\n",
    "$$\\text{acc_train} = 1 - \\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}},$$\n",
    "\n",
    "$$ \\text{acc_val} = 1 - \\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}.$$\n",
    "\n",
    "Note that $\\frac{\\sum{\\text{y_train}}}{\\text{len(y_train)}}$ reflects the proportion of students who defaulted on their loan in the training set, and $\\frac{\\sum{\\text{y_val}}}{\\text{len(y_val)}}$ reflects the proportion of students who defaulted on their loan in the validation set.\n",
    "\n",
    "Compute the required accuracy in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nubaBMtpAbok",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.090022Z",
     "start_time": "2023-11-01T23:15:05.050445Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_train = 1-sum(y_train)/len(y_train)\n",
    "acc_val = 1-sum(y_val)/len(y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4InhueSWAbok"
   },
   "source": [
    "Run the code cell below to print the results to screen. What can you say about the baseline accuracy if we predict that no students defaulted (i.e., everyone belongs to the majority class)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "id": "7dxNszcMAbok",
    "outputId": "1ddc9e64-7ffa-4e92-f11e-1d46a9ab3365",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.104360Z",
     "start_time": "2023-11-01T23:15:05.057576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve guess train and validation 0.778 0.75\n"
     ]
    }
   ],
   "source": [
    "print ( 'Naïve guess train and validation', acc_train , acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJhoY64TAbok"
   },
   "source": [
    "\n",
    "**Answer Questions 2 & 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gellnc1OAbok"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5 - Train a decision tree using the default settings\n",
    "\n",
    "The easiest way to create a decision tree model is by using the function `DecisionTreeClassifier()`. This function is part of the `tree` module of `Scikit-learn` (`sklearn`).\n",
    "\n",
    "As we will see, there are ways to improve the accuracy of our tree. For now, let's build a classifier using the default settings.\n",
    "\n",
    "In the code cell below, use `DecisionTreeClassifier()` to define a classifier `clf` . Next, use the method `fit()` of your classifier to fit your training sets, `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hwVF4uU-Abol",
    "outputId": "6b5d17fe-f35a-4402-bd10-f5e196e01987",
    "ExecuteTime": {
     "end_time": "2023-11-01T23:15:05.458710Z",
     "start_time": "2023-11-01T23:15:05.060159Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m clf \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mDecisionTreeClassifier()\n\u001B[0;32m----> 2\u001B[0m clf\u001B[38;5;241m.\u001B[39mfit(X_train,y_train)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[0;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    930\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[1;32m    931\u001B[0m \n\u001B[1;32m    932\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    956\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 959\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_fit(\n\u001B[1;32m    960\u001B[0m         X,\n\u001B[1;32m    961\u001B[0m         y,\n\u001B[1;32m    962\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[1;32m    963\u001B[0m         check_input\u001B[38;5;241m=\u001B[39mcheck_input,\n\u001B[1;32m    964\u001B[0m     )\n\u001B[1;32m    965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:284\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_classification:\n\u001B[0;32m--> 284\u001B[0m     check_classification_targets(y)\n\u001B[1;32m    285\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcopy(y)\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/multiclass.py:215\u001B[0m, in \u001B[0;36mcheck_classification_targets\u001B[0;34m(y)\u001B[0m\n\u001B[1;32m    207\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    210\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel-sequences\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    214\u001B[0m ]:\n\u001B[0;32m--> 215\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    216\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown label type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Maybe you are trying to fit a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassifier, which expects discrete classes on a \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregression target with continuous values.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    219\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa8TceT9Abol"
   },
   "source": [
    "Run the code cell below to visualize the new scores on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kceHGPBdAbol",
    "outputId": "39a19989-5eed-4bfc-fa63-6b5aa1f1f92b",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.444965Z"
    }
   },
   "outputs": [],
   "source": [
    "print ( 'Full tree guess train/validation ',clf.score(X_train, y_train),clf.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyQ7HCZHAbol"
   },
   "source": [
    "\n",
    "**Answer Questions 4 & 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GBrGJ8EAbol"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6 - Train a decision tree using  different maximum depths for the tree\n",
    "\n",
    "One way we can optimise the decision tree algorithm is by adjusting the maximum depth of the tree. This process is an example of pre-pruning. \n",
    "\n",
    "In the following the example, we will compute the score for  a decision tree on the same data with `max_depth = 15`.\n",
    "\n",
    "We begin by defining the variables `bestdepth` and `bestscore`, assuming the *worst case scenario*. Run the code cell below to inizialise the variable as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bE1y7csxAbol",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.446153Z"
    }
   },
   "outputs": [],
   "source": [
    "bestdepth=-1\n",
    "bestscore=0\n",
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlixZDIGAbol"
   },
   "source": [
    "Next, we will write a for loop to progressively compute the new train/validation scores for different depths.\n",
    "\n",
    "Here is the pseudocode for the for loop you will need to implement:\n",
    "\n",
    "```python\n",
    "\n",
    "for i in range(max_depth):\n",
    "    # compute new classifier clf with depth = max_depth = i+1\n",
    "    # fit the X and y training sets with the new classifier\n",
    "    # compute the updated trainscore using .score() on the training set \n",
    "    # compute the updated valscore using .score() on the validation set\n",
    "    # print the scores\n",
    "    print ( 'Depth:', i+1, 'Training Score:', trainscore, 'Validation Score:', valscore)\n",
    "     \n",
    "    # if valscore is better than bestscore:\n",
    "        # update the value of bestscore\n",
    "        # increase bestdepth by one unit\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4gTgig9Abom",
    "outputId": "5b5d8da6-5852-45c2-9fba-22da48410916",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.447895Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(max_depth):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i+1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    trainscore=clf.score(X_train,y_train)\n",
    "    valscore=clf.score(X_val,y_val)\n",
    "    print( 'Depth:', i+1, 'Train Score:', trainscore, 'Validation Score:', valscore)\n",
    "\n",
    "    if valscore>bestscore:\n",
    "        bestscore=valscore\n",
    "        bestdepth=i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tdULOXaAbon"
   },
   "source": [
    "Choose the most appropriate tree depth\n",
    "\n",
    "**Answer Questions 6 & 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4QG6BLkAbon"
   },
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7 - Retrain the best classifier using all the samples\n",
    "\n",
    "For the last part of this assignment, retrain the best classifier using all the samples from the training and the validation sets *together*. \n",
    "\n",
    "We begin by re-defining our `X_trainval` and `y_trainval`. Below, we have defined `X_trainval` for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IA3095eAbon",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.448797Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainval=X[:trainsize + trainplusvalsize,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQenih4Abon"
   },
   "source": [
    "Following the syntax given above, define `y_trainval`.\n",
    "\n",
    "Again, remember that `y` is a 1D array! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kcv3Xl5lAbon",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.449865Z"
    }
   },
   "outputs": [],
   "source": [
    "y_trainval=y[:trainsize + trainplusvalsize]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-A8VmvMAbon"
   },
   "source": [
    "To re-train the sets using the best classifier, re-define `clf`  using `DecisionTreeClassifier()` with `max_depth` equal to the `bestdepth` computed in Part 6. Next, fit the classifiers to the sets just defined above.\n",
    "\n",
    "Complete the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZEkT3G7Abon",
    "outputId": "7a150eb2-1dd9-437e-e241-e510aa7c3546",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.450840Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=bestdepth)\n",
    "clf.fit(X_trainval,y_trainval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVanCeynAboo"
   },
   "source": [
    "Use the function `score()` to compute the score on both the test sets. Assign the result to `test_score`.\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NalKg-5rAboo",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.451415Z"
    }
   },
   "outputs": [],
   "source": [
    "test_score = clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THDARKTbAboo",
    "outputId": "3df5ef59-aacb-45ca-b9bd-9ba42cb76d55",
    "ExecuteTime": {
     "start_time": "2023-11-01T23:15:05.452163Z"
    }
   },
   "outputs": [],
   "source": [
    "print('testing set score', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ47GtlnAboo"
   },
   "source": [
    " What do you observe?\n",
    "\n",
    "**Answer Questions 8 & 9**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "colab": {
   "name": "Module10_LoanDataset_Solutions.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
